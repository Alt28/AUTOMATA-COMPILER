================================================================================
                    GAL LANGUAGE LEXER - COMPLETE EXPLANATION
================================================================================

This document provides a detailed explanation of the lexer.py file which performs
lexical analysis (tokenization) for the GAL (Grow A Language) programming language.

================================================================================
                              TABLE OF CONTENTS
================================================================================

1. Overview & Purpose
2. Constants & Character Sets
3. Delimiter Sets
4. Token Types
5. Classes
   5.1 Position Class
   5.2 LexicalError Class
   5.3 Token Class
   5.4 Lexer Class
6. Main Tokenization Logic
7. Reserved Word Recognition (Keyword Parsing)
8. Operator & Symbol Handling
9. Number Literal Parsing
10. String & Character Literal Parsing
11. Comment Handling
12. Error Detection & Reporting
13. Usage Examples

================================================================================
1. OVERVIEW & PURPOSE
================================================================================

The lexer is the FIRST PHASE of compiling/interpreting a GAL program. Its job is to:

1. READ source code character by character
2. GROUP characters into meaningful units called TOKENS
3. CLASSIFY each token (keyword, identifier, number, operator, etc.)
4. DETECT lexical errors (invalid characters, malformed numbers, etc.)
5. TRACK position information (line and column numbers) for error reporting

Example:
   Source code:  "seed x = 42;"
   Tokens:       [seed, x, =, 42, ;]
   Types:        [KEYWORD, IDENTIFIER, OPERATOR, INTEGER, SEMICOLON]

================================================================================
2. CONSTANTS & CHARACTER SETS
================================================================================

These define the valid characters for different token types:

ZERO = '0'
   - The digit zero (special case for leading zeros)

DIGIT = '123456789'
   - Non-zero digits

ZERODIGIT = ZERO + DIGIT
   - All digits (0-9)
   - Used for: numeric literals, identifiers

LOW_ALPHA = 'abcdefghijklmnopqrstuvwxyz'
UPPER_ALPHA = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'
   - Lowercase and uppercase letters

ALPHA = LOW_ALPHA + UPPER_ALPHA
   - All letters (a-z, A-Z)
   - Used for: keywords, identifiers

ALPHANUM = ALPHA + ZERODIGIT + '_'
   - Letters, digits, and underscore
   - Valid characters for identifiers after the first character
   - Example: "player_score123" is valid

================================================================================
3. DELIMITER SETS
================================================================================

Delimiters are characters that can legally appear AFTER certain tokens.
Different token types have different valid delimiters.

space_delim = {' ', ';', '{'}
   - Used after keywords like 'seed', 'tree', 'leaf'
   - Ensures keywords are separated from what follows

delim2 = {';', ':'}
   - Used after 'soil' (default case in switch)

delim3 = {'{'}
   - Used after 'tend' (do-while), 'wither' (else)

delim4 = {':', '('}
   - Used after 'bud' (else-if), 'cultivate' (for), 'harvest' (switch)

delim6 = {';', ',', '=', '>', '<', '!', '}', ')', '('}
   - Used after 'spring' (if), 'plant' (output), 'water' (input)

idf_delim = {' ', ',', ';', '(', ')', '{', '}', '[', ']', ':', '+', '-', '*', '/', '%', '>', '<', '=', '\t', '\n'}
   - Valid delimiters after identifiers
   - Example: "x + 5" - space after 'x' is valid

whlnum_delim = {';', ' ', ',', '}', ']', ')', ':', '+', '-', '*', '/', '%', '=', '>', '<', '!', '&', '|', '\t', '\n'}
   - Valid delimiters after integer literals
   - Example: "42 + x" - space after '42' is valid

decim_delim = {'}', ';', ',', '+', '-', '*', '/', '%', '=', '>', '<', '!', '&', '|', ' ', '\t', '\n', ')'}
   - Valid delimiters after double/float literals
   - Example: "3.14 * r" - space after '3.14' is valid

================================================================================
4. TOKEN TYPES
================================================================================

The lexer recognizes these token types:

--- RESERVED WORDS (Keywords) ---

TT_RW_WATER       = 'water'     - Input function
TT_RW_PLANT       = 'plant'     - Output function
TT_RW_SEED        = 'seed'      - Integer type
TT_RW_LEAF        = 'leaf'      - Character type
TT_RW_BRANCH      = 'branch'    - Boolean type
TT_RW_TREE        = 'tree'      - Double/float type
TT_RW_SPRING      = 'spring'    - If statement
TT_RW_WITHER      = 'wither'    - Else statement
TT_RW_BUD         = 'bud'       - Else-if statement
TT_RW_HARVEST     = 'harvest'   - Switch statement
TT_RW_GROW        = 'grow'      - While loop
TT_RW_CULTIVATE   = 'cultivate' - For loop
TT_RW_TEND        = 'tend'      - Do-while loop
TT_RW_EMPTY       = 'empty'     - Void return type
TT_RW_PRUNE       = 'prune'     - Break statement
TT_RW_SKIP        = 'skip'      - Continue statement
TT_RW_RECLAIM     = 'reclaim'   - Return statement
TT_RW_ROOT        = 'root'      - Main function
TT_RW_POLLINATE   = 'pollinate' - Function definition
TT_RW_VARIETY     = 'variety'   - Case in switch
TT_RW_FERTILE     = 'fertile'   - Constant declaration
TT_RW_SOIL        = 'soil'      - Default case in switch
TT_RW_BUNDLE      = 'bundle'    - Struct definition

--- OPERATORS & SYMBOLS ---

TT_PLUS       = '+'    - Addition
TT_MINUS      = '-'    - Subtraction
TT_MUL        = '*'    - Multiplication
TT_DIV        = '/'    - Division
TT_MOD        = '%'    - Modulo
TT_EXP        = '**'   - Exponentiation
TT_EQ         = '='    - Assignment
TT_EQTO       = '=='   - Equality comparison
TT_PLUSEQ     = '+='   - Add and assign
TT_MINUSEQ    = '-='   - Subtract and assign
TT_MULTIEQ    = '*='   - Multiply and assign
TT_DIVEQ      = '/='   - Divide and assign
TT_MODEQ      = '%='   - Modulo and assign
TT_LT         = '<'    - Less than
TT_GT         = '>'    - Greater than
TT_LTEQ       = '<='   - Less than or equal
TT_GTEQ       = '>='   - Greater than or equal
TT_NOTEQ      = '!='   - Not equal
TT_AND        = '&&'   - Logical AND
TT_OR         = '||'   - Logical OR
TT_NOT        = '!'    - Logical NOT
TT_INCREMENT  = '++'   - Increment
TT_DECREMENT  = '--'   - Decrement

--- DELIMITERS & PUNCTUATION ---

TT_LPAREN     = '('    - Left parenthesis
TT_RPAREN     = ')'    - Right parenthesis
TT_SEMICOLON  = ';'    - Statement terminator
TT_COMMA      = ','    - Separator
TT_COLON      = ':'    - Used in switch cases
TT_BLOCK_START = '{'   - Block start
TT_BLOCK_END   = '}'   - Block end
TT_LSQBR      = '['    - Left square bracket (arrays)
TT_RSQBR      = ']'    - Right square bracket
TT_DOT        = '.'    - Struct member access
TT_NEGATIVE   = '~'    - Unary negation

--- LITERALS ---

TT_IDENTIFIER  = 'id'        - Variable/function names
TT_INTEGERLIT  = 'intlit'    - Integer numbers (e.g., 42)
TT_DOUBLELIT   = 'dbllit'    - Float numbers (e.g., 3.14)
TT_STRINGLIT   = 'strnglit'  - String literals (e.g., "hello")
TT_CHARLIT     = 'chrlit'    - Character literals (e.g., 'a')

--- SPECIAL ---

TT_EOF        = 'EOF'   - End of file marker
TT_NL         = '\n'    - Newline token

================================================================================
5. CLASSES
================================================================================

5.1 Position Class
------------------
Tracks the current position in the source code.

class Position:
    def __init__(self, index, ln, col=0):
        self.index = index  # Character index in source code (0-based)
        self.ln = ln        # Line number (1-based)
        self.col = col      # Column number (0-based)

    def advance(self, current_char):
        """Move to next character position"""
        self.index += 1
        self.col += 1
        
        if current_char == '\n':
            self.ln += 1    # New line
            self.col = 0    # Reset column
        
        return self
    
    def copy(self):
        """Create a copy of current position for error reporting"""
        return Position(self.index, self.ln, self.col)

Example usage:
   Source: "seed x = 5;"
   Position at 's': index=0, ln=1, col=0
   Position at 'x': index=5, ln=1, col=5
   Position at '5': index=9, ln=1, col=9

5.2 LexicalError Class
-----------------------
Represents a lexical error with position and description.

class LexicalError:
    def __init__(self, pos, details):
        self.pos = pos          # Position object where error occurred
        self.details = details  # Error description

    def as_string(self):
        """Format error message for display"""
        self.details = self.details.replace('\n', '\\n')
        return f"Ln {self.pos.ln}, Col {self.pos.col}: {self.details}"

Example error:
   "Ln 5, Col 12: Invalid delimiter '+' after 'seed'"

5.3 Token Class
----------------
Represents a single token.

class Token:
    def __init__(self, type_, value=None, line=1):
        self.type = type_    # Token type (e.g., TT_IDENTIFIER)
        self.value = value   # Token text (e.g., "player_score")
        self.line = line     # Line number where token appears

Example tokens:
   Token(TT_RW_SEED, "seed", 1)       - 'seed' keyword on line 1
   Token(TT_IDENTIFIER, "x", 1)       - identifier 'x' on line 1
   Token(TT_INTEGERLIT, "42", 1)      - integer 42 on line 1

5.4 Lexer Class
----------------
The main lexer that performs tokenization.

class Lexer:
    def __init__(self, source_code):
        self.source_code = source_code        # Input code string
        self.pos = Position(-1, 1, -1)        # Start before first char
        self.current_char = None              # Current character
        self.advance()                        # Move to first character

    def advance(self):
        """Move to next character in source code"""
        self.pos.advance(self.current_char)
        # Get character at current index, or None if at end
        self.current_char = (self.source_code[self.pos.index] 
                             if self.pos.index < len(self.source_code) 
                             else None)

    def make_tokens(self):
        """Main tokenization method - returns (tokens, errors)"""
        # ... (explained in section 6)

================================================================================
6. MAIN TOKENIZATION LOGIC
================================================================================

The make_tokens() method is the core of the lexer. It:

1. Loops through each character in the source code
2. Identifies what type of token starts at that position
3. Collects characters until the token is complete
4. Creates a Token object and adds it to the tokens list
5. Detects and reports errors

Flow:
   while self.current_char != None:
       if self.current_char in ALPHA:
           # Could be keyword or identifier
           [Parse keyword or identifier]
       
       elif self.current_char in ZERODIGIT:
           # Number literal
           [Parse number]
       
       elif self.current_char == '"':
           # String literal
           [Parse string]
       
       elif self.current_char == "'":
           # Character literal
           [Parse character]
       
       elif self.current_char == '+':
           # Operator (could be +, ++, or +=)
           [Parse operator]
       
       # ... handle other characters

================================================================================
7. RESERVED WORD RECOGNITION (Keyword Parsing)
================================================================================

Keywords are recognized using nested if-statements that check each letter
in sequence. This is called "character-by-character matching".

Example: Recognizing the keyword "seed"

   if self.current_char == "s":      # First letter
       ident_str += self.current_char
       self.advance()
       
       if self.current_char == "e":  # Second letter
           ident_str += self.current_char
           self.advance()
           
           if self.current_char == "e":  # Third letter
               ident_str += self.current_char
               self.advance()
               
               if self.current_char == "d":  # Fourth letter
                   ident_str += self.current_char
                   self.advance()
                   
                   # Verify delimiter after "seed"
                   if self.current_char == ';':
                       # Error: seed must be followed by identifier
                       errors.append(LexicalError(pos, 
                           "Expected an identifier after 'seed'"))
                   elif self.current_char in space_delim:
                       # Valid: seed followed by space/delimiter
                       tokens.append(Token(TT_RW_SEED, "seed", line))
                   elif self.current_char not in ALPHANUM:
                       # Error: invalid character after seed
                       errors.append(LexicalError(pos, 
                           f"Invalid delimiter '{self.current_char}' after 'seed'"))

Why nested if-statements?
   - Efficient: Only checks relevant characters
   - Clear: Easy to see which keyword is being matched
   - Flexible: Can handle keywords of different lengths

All Keywords Recognized:
   - branch (6 letters)
   - bud (3 letters)
   - bundle (6 letters)
   - cultivate (9 letters)
   - empty (5 letters)
   - fertile (7 letters)
   - grow (4 letters)
   - harvest (7 letters)
   - leaf (4 letters)
   - plant (5 letters)
   - pollinate (9 letters)
   - prune (5 letters)
   - reclaim (7 letters)
   - root (4 letters)
   - seed (4 letters)
   - skip (4 letters)
   - soil (4 letters)
   - spring (6 letters)
   - sunshine (8 letters) - boolean true
   - tend (4 letters)
   - tree (4 letters)
   - variety (7 letters)
   - water (5 letters)
   - wither (6 letters)
   - frost (5 letters) - boolean false

Special Keyword Validation:
   - Data types (seed, leaf, branch, tree) MUST be followed by an identifier
     Example: "seed x" ✓   "seed;" ✗
   
   - Some keywords require specific delimiters:
     * spring, bud, harvest, cultivate, grow require '(' or valid delimiter
     * soil, fertile require ';' or ':'
     * wither, tend require '{'

================================================================================
8. OPERATOR & SYMBOL HANDLING
================================================================================

Operators can be single or multi-character:

Single Character Operators:
   + - * / % = < > ! ~ ( ) [ ] { } ; , : .

Multi-Character Operators:
   ++ -- += -= *= /= %= == != <= >= && ||

Recognition Strategy:
   1. Read first character
   2. Check if next character forms a multi-char operator
   3. Create appropriate token

Example: Handling '+' operator

   elif self.current_char == "+":
       ident_str = self.current_char
       pos = self.pos.copy()
       self.advance()
       
       if self.current_char == "+":
           # Found ++ (increment)
           # But only valid after identifier or integer
           if len(tokens) > 0 and tokens[-1].type in [TT_IDENTIFIER, TT_INTEGERLIT]:
               ident_str += self.current_char
               self.advance()
               tokens.append(Token(TT_INCREMENT, "++", line))
           else:
               # Error: ++ without valid operand
               errors.append(LexicalError(pos, 
                   "Consecutive operators '++' are not allowed"))
       
       elif self.current_char == "=":
           # Found += (add and assign)
           ident_str += self.current_char
           self.advance()
           tokens.append(Token(TT_PLUSEQ, "+=", line))
       
       else:
           # Just a single +
           # Check for consecutive operators like "+ +"
           if self.current_char in '+-*/%':
               errors.append(LexicalError(pos, 
                   f"Consecutive operators not allowed"))
           else:
               tokens.append(Token(TT_PLUS, "+", line))

Error Detection for Operators:
   - Consecutive operators: "+ +" or "* /"
   - Invalid delimiters: "+$" or "* @"
   - Incomplete operators: single '&' instead of '&&'

================================================================================
9. NUMBER LITERAL PARSING
================================================================================

The lexer recognizes three types of numeric literals:

1. INTEGERS: 42, 0, 123
2. DOUBLES/FLOATS: 3.14, 0.5, 2.0
3. SCIENTIFIC NOTATION: 1.5e10, 2.3e-5

Number Parsing Algorithm:

   elif self.current_char in ZERODIGIT:
       ident_str = ""
       pos = self.pos.copy()
       integer_digit_count = 0
       fractional_digit_count = 0
       dot_count = 0
       has_e = False
       
       # Step 1: Read integer part (before decimal point)
       while self.current_char in ZERODIGIT:
           integer_digit_count += 1
           if integer_digit_count > 16:
               # Error: integer too long
               errors.append(LexicalError(pos, 
                   "Integer part exceeds maximum of 16 digits"))
               [consume rest and break]
           
           ident_str += self.current_char
           self.advance()
       
       # Step 2: Check for decimal point
       if self.current_char == ".":
           dot_count = 1
           ident_str += self.current_char
           self.advance()
           
           # Must have digits after decimal point
           if self.current_char not in ZERODIGIT:
               errors.append(LexicalError(pos, 
                   "Decimal point must be followed by digits"))
           
           # Read fractional part
           while self.current_char in ZERODIGIT:
               fractional_digit_count += 1
               if fractional_digit_count > 7:
                   # Error: too many decimal places
                   errors.append(LexicalError(pos, 
                       "Fractional part exceeds maximum of 7 digits"))
                   [consume rest and break]
               
               ident_str += self.current_char
               self.advance()
       
       # Step 3: Check for scientific notation (e.g., 1.5e10)
       if self.current_char in 'eE' and dot_count == 1:
           has_e = True
           ident_str += self.current_char
           self.advance()
           
           # Handle optional sign after 'e'
           if self.current_char in '+-':
               ident_str += self.current_char
               self.advance()
           
           # Must have digits after 'e'
           if self.current_char not in ZERODIGIT:
               errors.append(LexicalError(pos, 
                   "'e' must be followed by digits"))
           
           # Read exponent digits
           while self.current_char in ZERODIGIT:
               ident_str += self.current_char
               self.advance()
       
       # Step 4: Validate delimiter and type checking
       if dot_count == 0:  # INTEGER
           # Check if this is after a tree type declaration
           # tree only accepts doubles, not integers
           [Check for tree type error]
           
           # Check delimiter
           if self.current_char not in whlnum_delim:
               [Handle invalid delimiter]
           
           # Remove leading zeros: "0042" -> "42"
           ident_str = ident_str.lstrip("0") or "0"
           tokens.append(Token(TT_INTEGERLIT, ident_str, line))
       
       else:  # DOUBLE/FLOAT
           # Check delimiter
           if self.current_char not in decim_delim:
               errors.append(LexicalError(pos, 
                   f"Invalid delimiter after '{ident_str}'"))
           
           # Format: "1.50" -> "1.5", but "1.0" stays "1.0"
           if not has_e:
               [Format number properly]
           
           tokens.append(Token(TT_DOUBLELIT, ident_str, line))

Special Number Validations:

1. Underscore in numbers (NOT ALLOWED):
   "22_3" -> Error: "Underscore cannot be used in numeric literals"

2. Number followed by letter/word:
   "111seed" -> Error: "Reserved word cannot start with a number"
   "42abc" -> Error: "Identifiers cannot start with a number"

3. Leading zeros:
   "0042" -> Normalized to "42"
   "0.5" -> Valid double

4. Type compatibility:
   tree x = 42;    -> Error: tree variables need double (use 42.0)
   seed x = "5";   -> Error: seed variables need integer
   branch x = 'a'; -> Error: branch needs sunshine/frost

================================================================================
10. STRING & CHARACTER LITERAL PARSING
================================================================================

10.1 STRING LITERALS
--------------------

Strings are enclosed in double quotes: "hello world"

Parsing Algorithm:

   elif self.current_char == '"':
       string = ''
       pos = self.pos.copy()
       escape_character = False
       string += self.current_char  # Include opening quote
       self.advance()
       
       # Supported escape sequences
       escape_characters = {
           'n': '\n',   # Newline
           't': '\t',   # Tab
           '{': '\\{',  # Literal {
           '}': '\\}'   # Literal }
       }
       
       # Read until closing quote (or error)
       while self.current_char != '"' or escape_character:
           if escape_character:
               # Process escape sequence
               string += escape_characters.get(self.current_char, 
                                               self.current_char)
               escape_character = False
           else:
               if self.current_char == '\\':
                   # Start escape sequence
                   escape_character = True
               elif self.current_char == '\n':
                   # Error: newline in string
                   break
               else:
                   string += self.current_char
           
           self.advance()
       
       # Check for closing quote
       if self.current_char == '"':
           string += self.current_char
           self.advance()
       else:
           errors.append(LexicalError(pos, 
               f"Missing closing '\"' after '{string}'"))
       
       # Validate delimiter after string
       if self.current_char not in delim23:
           errors.append(LexicalError(pos, 
               f"Invalid delimiter after string"))
       
       # Type checking
       [Check if string assigned to wrong type]
       
       tokens.append(Token(TT_STRINGLIT, string, line))

String Validations:

1. Unterminated string:
   "hello    -> Error: Missing closing '"'

2. Newline in string:
   "hello
   world"    -> Error: Newline breaks string

3. Purely numeric string (NOT ALLOWED):
   "42"      -> Error: String cannot contain only numeric values
   "3.14"    -> Error: String cannot contain only numeric values

4. Type compatibility:
   branch x = "hello";  -> Error: branch needs sunshine/frost
   seed x = "42";       -> Error: seed needs integer

5. Escape sequences:
   "hello\nworld" -> Valid (newline)
   "value: \{x\}" -> Valid (literal braces)

10.2 CHARACTER LITERALS
------------------------

Characters are enclosed in single quotes: 'a'

Parsing Algorithm:

   elif self.current_char == "'":
       string = ''  # Full text including quotes
       char = ''    # Actual character value
       pos = self.pos.copy()
       string += self.current_char  # Include opening quote
       self.advance()
       
       # Read until closing quote
       while self.current_char != "'":
           if self.current_char == '\n':
               break  # Error condition
           
           elif self.current_char == '\\':
               # Handle escape sequence
               string += self.current_char
               self.advance()
               
               if self.current_char in "'\\nt":
                   # Valid escape: \', \\, \n, \t
                   char += f"\\{self.current_char}"
                   string += self.current_char
               else:
                   # Invalid escape sequence
                   errors.append(LexicalError(pos, 
                       f"Invalid escape sequence '\\{self.current_char}'"))
                   [consume rest and break]
           
           else:
               string += self.current_char
               char += self.current_char
           
           self.advance()
       
       # Check for closing quote
       if self.current_char == "'":
           string += self.current_char
           self.advance()
       else:
           errors.append(LexicalError(pos, 
               f"Missing closing \"'\" after '{string}'"))
       
       # Validate character length
       if len(char) > 1 and not (len(char) == 2 and char.startswith('\\')):
           errors.append(LexicalError(pos, 
               f"Character literal exceeds maximum length of 1"))
       elif len(char) == 0:
           errors.append(LexicalError(pos, 
               "Empty character literal"))
       
       # Validate delimiter
       if self.current_char not in delim23:
           errors.append(LexicalError(pos, 
               f"Invalid delimiter after '{string}'"))
       
       # Type checking
       [Check if char assigned to wrong type]
       
       tokens.append(Token(TT_CHARLIT, string, line))

Character Literal Validations:

1. Empty character:
   ''     -> Error: Empty character literal

2. Too many characters:
   'ab'   -> Error: Exceeds maximum length of 1
   'hello' -> Error: Exceeds maximum length of 1

3. Valid escape sequences:
   '\n'   -> Valid (newline)
   '\t'   -> Valid (tab)
   '\''   -> Valid (single quote)
   '\\'   -> Valid (backslash)

4. Invalid escape sequences:
   '\x'   -> Error: Invalid escape sequence '\x'
   '\5'   -> Error: Invalid escape sequence '\5'

5. Type compatibility:
   branch x = 'a';  -> Error: branch needs sunshine/frost
   seed x = 'a';    -> Error: seed needs integer
   tree x = 'a';    -> Error: tree needs double

================================================================================
11. COMMENT HANDLING
================================================================================

GAL supports two types of comments:

1. SINGLE-LINE COMMENTS: // comment text
2. MULTI-LINE COMMENTS: /* comment text */

Comments are NOT added to the token list - they are skipped.

11.1 Single-Line Comments
--------------------------

   elif self.current_char == "/":
       if self.current_char == "/":  # Check for second /
           # Consume until newline or end of file
           while self.current_char != '\n' and self.current_char != None:
               self.advance()
           # Comment is skipped, continue to next token

Example:
   seed x = 5;  // This is a comment
   ^^^^^^^^^^^^  <- Tokens
                 ^^^^^^^^^^^^^^^^^^^ <- Skipped

11.2 Multi-Line Comments
-------------------------

   elif self.current_char == "/":
       if self.current_char == "*":  # Check for opening /*
           # Consume until closing */
           while self.current_char != None:
               if self.current_char == "*" and next_char == "/":
                   # Found closing */
                   self.advance()  # Skip *
                   self.advance()  # Skip /
                   break
               
               if self.current_char == '\n':
                   line += 1  # Track line numbers inside comment
               
               self.advance()
           
           # Check if comment was closed
           if self.current_char == None:
               errors.append(LexicalError(pos, 
                   "Missing closing '*/' in comment"))

Example:
   /* This is a
      multi-line
      comment */
   seed x = 5;
   ^^^^^^^^^^^^^^^ <- Skipped
                ^^^^^^^^^^^^ <- Tokens

Unterminated Comment Error:
   /* This comment never closes
   seed x = 5;
   
   -> Error: Missing closing '*/' after '/* This comment...'

================================================================================
12. ERROR DETECTION & REPORTING
================================================================================

The lexer detects many types of errors:

12.1 Invalid Characters
------------------------
   seed x = $;
            ^ Error: Illegal Character '$'

12.2 Invalid Delimiters
-----------------------
   seed x+5;
         ^ Error: Invalid delimiter '+' after 'seed'
   
   plant@();
        ^ Error: Invalid delimiter '@' after 'plant'

12.3 Malformed Numbers
----------------------
   3.14.159
       ^ Error: Multiple decimal points
   
   123456789012345678
   ^^^^^^^^^^^^^^^^^^ Error: Integer exceeds maximum of 16 digits
   
   1.234567890
     ^^^^^^^^^ Error: Fractional part exceeds maximum of 7 digits
   
   22_3
     ^ Error: Underscore cannot be used in numeric literals
   
   111seed
   ^^^^^^^ Error: Reserved word cannot start with a number

12.4 Missing Identifiers
-------------------------
   seed ;
        ^ Error: Expected an identifier after 'seed'
   
   tree ,
        ^ Error: Expected an identifier after 'tree'

12.5 Type Mismatches
--------------------
   tree x = 42;
            ^^ Error: Tree variables cannot be assigned integer literals
   
   seed y = "hello";
            ^^^^^^^ Error: Seed variables cannot be assigned string literals
   
   branch flag = 'a';
                 ^^^ Error: Branch variables need sunshine/frost

12.6 String/Character Errors
-----------------------------
   "unterminated string
   ^^^^^^^^^^^^^^^^^^^^^ Error: Missing closing '"'
   
   'ab'
   ^^^^ Error: Character literal exceeds maximum length
   
   ''
   ^^ Error: Empty character literal
   
   'x\z'
      ^ Error: Invalid escape sequence '\z'

12.7 Consecutive Operators
---------------------------
   5 + + 3
       ^ Error: Consecutive operators '+ +' are not allowed
   
   x * / 2
       ^ Error: Consecutive operators '* /' are not allowed

12.8 Identifier Length
----------------------
   verylongidentifiername123
   ^^^^^^^^^^^^^^^^^^^^^^^^^ Error: Exceeds maximum length of 16 characters

12.9 Symbol Prefix Errors
--------------------------
   _seed
   ^^^^^ Error: Reserved word cannot start with a symbol
   
   _myvar
   ^^^^^^ Error: Identifiers cannot start with a symbol

================================================================================
13. USAGE EXAMPLES
================================================================================

Example 1: Simple Variable Declaration
---------------------------------------

Input:
   seed x = 42;

Tokens Generated:
   Token(TT_RW_SEED, "seed", 1)      - Keyword
   Token(TT_IDENTIFIER, "x", 1)      - Identifier
   Token(TT_EQ, "=", 1)              - Assignment operator
   Token(TT_INTEGERLIT, "42", 1)     - Integer literal
   Token(TT_SEMICOLON, ";", 1)       - Statement terminator
   Token(TT_EOF, "", 1)              - End of file

Example 2: If Statement
-----------------------

Input:
   spring (x > 5) {
       water("Greater");
   }

Tokens Generated:
   Token(TT_RW_SPRING, "spring", 1)       - If keyword
   Token(TT_LPAREN, "(", 1)               - Left paren
   Token(TT_IDENTIFIER, "x", 1)           - Identifier
   Token(TT_GT, ">", 1)                   - Greater than
   Token(TT_INTEGERLIT, "5", 1)           - Integer
   Token(TT_RPAREN, ")", 1)               - Right paren
   Token(TT_BLOCK_START, "{", 1)          - Block start
   Token(TT_NL, "\n", 1)                  - Newline
   Token(TT_RW_WATER, "water", 2)         - Output function
   Token(TT_LPAREN, "(", 2)               - Left paren
   Token(TT_STRINGLIT, "\"Greater\"", 2)  - String literal
   Token(TT_RPAREN, ")", 2)               - Right paren
   Token(TT_SEMICOLON, ";", 2)            - Semicolon
   Token(TT_NL, "\n", 2)                  - Newline
   Token(TT_BLOCK_END, "}", 3)            - Block end
   Token(TT_EOF, "", 3)                   - End of file

Example 3: Error Detection
---------------------------

Input:
   seed 123abc;

Errors Generated:
   Ln 1, Col 5: Identifiers cannot start with a number: '123abc'

Explanation:
   - 'seed' is recognized as keyword
   - '123' starts being parsed as number
   - 'abc' follows, making it invalid
   - Error is reported at column 5 (where '1' starts)

Example 4: Float with Scientific Notation
------------------------------------------

Input:
   tree gravity = 9.8e-10;

Tokens Generated:
   Token(TT_RW_TREE, "tree", 1)           - Keyword
   Token(TT_IDENTIFIER, "gravity", 1)     - Identifier
   Token(TT_EQ, "=", 1)                   - Assignment
   Token(TT_DOUBLELIT, "9.8e-10", 1)      - Scientific notation
   Token(TT_SEMICOLON, ";", 1)            - Semicolon
   Token(TT_EOF, "", 1)                   - End of file

================================================================================
                              END OF DOCUMENT
================================================================================

This lexer serves as the first phase of the GAL compiler/interpreter pipeline:

   SOURCE CODE -> [LEXER] -> TOKENS -> [PARSER] -> AST -> [INTERPRETER/COMPILER]

The lexer's output (tokens and errors) is passed to the parser, which performs
syntax analysis to build an Abstract Syntax Tree (AST) for execution.
